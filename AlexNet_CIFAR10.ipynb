{"cells":[{"cell_type":"markdown","metadata":{"id":"UaX6ScG1ui6X"},"source":[]},{"cell_type":"markdown","metadata":{"id":"aAnCxtem9Bat"},"source":["# Resources\n","- https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","- https://blog.paperspace.com/alexnet-pytorch/\n","- https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py\n","- https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n","- https://en.wikipedia.org/wiki/AlexNet\n","- http://d2l.ai/chapter_convolutional-modern/alexnet.html"]},{"cell_type":"markdown","metadata":{"id":"Np1-0oJV1N7A"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1714973580736,"user":{"displayName":"Syed Rizvi","userId":"03690040082444449942"},"user_tz":300},"id":"Ji1IDa77saLk","outputId":"9e7e3d34-3782-4c99-e9d1-7747285b2ef4"},"outputs":[],"source":["# import pandas as pd # dataframes\n","# import torchvision.transforms as transforms\n","\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","import torchmetrics"]},{"cell_type":"markdown","metadata":{"id":"WMK_C_984PGq"},"source":["# Device Configuration"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1714973580736,"user":{"displayName":"Syed Rizvi","userId":"03690040082444449942"},"user_tz":300},"id":"TAMnRUzw4TJw","outputId":"bfea5c9d-92b6-41d2-b247-0356d82ac143"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda processing\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using {device} processing\")"]},{"cell_type":"markdown","metadata":{"id":"yINKpH7z1PN3"},"source":["# Load Datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2208,"status":"ok","timestamp":1714973582933,"user":{"displayName":"Syed Rizvi","userId":"03690040082444449942"},"user_tz":300},"id":"Mk2kKREM4-24","outputId":"a803696d-7e4d-4888-c1ac-951749f37bc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Training Size: 45000\n","Validation Size: 5000\n","Testing Size: 10000\n"]}],"source":["dir = './data'\n","download = True\n","transform = transforms.Compose( # define normalization transform\n","    [\n","      transforms.Resize((227,227)), # resize images to required minimum 227x227\n","      transforms.ToTensor(), # transform image to tensor and torch format\n","      transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)) # apply normalize across all the channels for the image\n","    ]\n",")\n","\n","# Get Datasets\n","dataset_train = datasets.CIFAR10(root = dir, download=download, transform=transform, train = True)\n","dataset_test = datasets.CIFAR10(root = dir, download=download, transform=transform, train = False)\n","\n","# Split the training dataset into a training set (90% samples) and a validation set (10% samples).\n","size_train = int(0.9 * len(dataset_train))\n","size_valid = len(dataset_train) - size_train\n","\n","dataset_train, dataset_valid = torch.utils.data.random_split(dataset_train, [size_train, size_valid])\n","\n","# Verify the sizes of the training and validation sets\n","print(f\"Training Size: {len(dataset_train)}\")\n","print(f\"Validation Size: {len(dataset_valid)}\")\n","print(f\"Testing Size: {len(dataset_test)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Explore and Visualize Data"]},{"cell_type":"markdown","metadata":{"id":"12rnML7-1THu"},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"HaOzGFEk19ik"},"outputs":[],"source":["class AlexNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","\n","            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            \n","            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            \n","            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            \n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(9216, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# TensorBoard"]},{"cell_type":"markdown","metadata":{"id":"ZzbGpSfs1ZWq"},"source":["# Hyperparameters & Loss Function"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"1d2pGJ3v2daI"},"outputs":[],"source":["learning_rates = [0.1, 0.01, 0.001, 0.0001]\n","batch_sizes = [32, 64]\n","epochs = [25] # 50\n","classes = 10\n","\n","loss_function = nn.CrossEntropyLoss() # Loss"]},{"cell_type":"markdown","metadata":{"id":"01Oyp3JV1Wrc"},"source":["# Define Training Function"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1714974132645,"user":{"displayName":"Syed Rizvi","userId":"03690040082444449942"},"user_tz":300},"id":"JzFTqtaM-Iy3"},"outputs":[],"source":["optimizations = True\n","\n","def TrainModel(optimizer, batch_size, learning_rate, num_epochs):\n","  print(f\"Training model using parameters:\")\n","  print(f\"    - Optimizer: {optimizer} \")\n","  print(f\"    - Batch Size: {batch_size} \")\n","  print(f\"    - Learning Rate: {learning_rate} \")\n","  print(f\"    - Epochs: {num_epochs} \")\n","  print()\n","\n","  # Model\n","  model = AlexNet(num_classes = classes).to(device)\n","\n","\n","  # Optimizer Function\n","  # this will help change the parameters of the model, influenced by the learning rate\n","  if optimizer == 'Adam':\n","    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","  elif optimizer == 'SGD':\n","    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9)\n","  else:\n","    return\n","\n","  # Data loaders\n","  # Data loaders split the data up into batches as determined by the batch size\n","  if optimizations: \n","    loader_train = torch.utils.data.DataLoader(dataset = dataset_train, batch_size = batch_size, shuffle = True, num_workers=4, pin_memory=True)\n","    loader_valid = torch.utils.data.DataLoader(dataset = dataset_valid, batch_size = batch_size, shuffle = False, num_workers=4, pin_memory=True)\n","  else:\n","    loader_train = torch.utils.data.DataLoader(dataset = dataset_train, batch_size = batch_size, shuffle = True)\n","    loader_valid = torch.utils.data.DataLoader(dataset = dataset_valid, batch_size = batch_size, shuffle = False)\n","\n","  # Metrics\n","  metric_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=classes).to(device)\n","  metric_f1 = torchmetrics.F1Score(task='multiclass', num_classes = classes).to(device)\n","\n","  # For Epoch\n","  for epoch in range(num_epochs):\n","    loss_epoch = 0\n","    for i, (inputs, targets) in enumerate(loader_train): # loop through each batch the dataloader has\n","      # Get the inputs and their target class\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      outputs = model(inputs) # feed the model the inputs, and get predictions off the inputs\n","      loss = loss_function(outputs, targets) # compare the preditions to the actual target values of the inputs\n","      loss.backward() # compute the gradients\n","      optimizer.step() # actually update the model parameters based off the gradients computed previously\n","\n","      loss_epoch += loss.item()\n","      if i%(round((len(loader_train)/3), -1)) == 0:\n","        print(f'Epoch {epoch+1}/{num_epochs}; Step: {i+1}/{len(loader_train)}')\n","        print(f'Loss: {loss.item():.4f}')\n","        print()\n","    \n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    model.eval() # set the model to eval mode so it does not train off the whole training/testing sets\n","    with torch.no_grad(): # disabling gradient calculation, since we're not computing gradients\n","      \n","      loss_epoch = loss_epoch/len(loader_train)\n","      metric_accuracy.reset()\n","      metric_f1.reset()\n","      for inputs, targets in loader_valid:\n","        inputs = inputs.to(device) # get test input\n","        targets = targets.to(device) # get the classes of the test input\n","        outputs = model(inputs) # predict the classification values of the test input\n","        predicted = torch.argmax(outputs.data, 1) # get the highest classification value\n","\n","        metric_accuracy.update(predicted, targets)\n","        metric_f1.update(predicted, targets)\n","\n","      print(f'Epoch: {epoch+1}/{num_epochs}')\n","      print(f'Loss: {loss_epoch:.4f}')\n","      print(f'Accuracy: {(100 * metric_accuracy.compute()):.4f}%')\n","      print(f'F1Score: {(100* metric_f1.compute()):.4f}%')\n","      print()\n","\n","      if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    model.train() # set model back in training mode"]},{"cell_type":"markdown","metadata":{},"source":["# Train Models"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":184169,"status":"error","timestamp":1714974593391,"user":{"displayName":"Syed Rizvi","userId":"03690040082444449942"},"user_tz":300},"id":"fOeDRd9VBZxq","outputId":"b79faa87-84f7-4e5b-d954-3f6f508a9cb5"},"outputs":[],"source":["for epoch in epochs:\n","  for batch_size in batch_sizes:\n","    for learning_rate in learning_rates:\n","      #TrainModel('Adam', batch_size, learning_rate, epoch)\n","      break"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model using parameters:\n","    - Optimizer: SGD \n","    - Batch Size: 16 \n","    - Learning Rate: 0.005 \n","    - Epochs: 3 \n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Personal Files\\Coding\\Github\\MLProj\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1/3\n","Accuracy: 54.3600%\n","F1Score: 54.3600%\n","\n","Epoch: 2/3\n","Accuracy: 65.3000%\n","F1Score: 65.3000%\n","\n","Epoch: 3/3\n","Accuracy: 72.0200%\n","F1Score: 72.0200%\n","\n"]}],"source":["TrainModel('SGD', 16, 0.005, 3)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model using parameters:\n","    - Optimizer: SGD \n","    - Batch Size: 32 \n","    - Learning Rate: 0.005 \n","    - Epochs: 3 \n","\n","Epoch 1/3; Step: 1/1407\n","Loss: 2.3029\n","\n","Epoch 1/3; Step: 471/1407\n","Loss: 2.2110\n","\n","Epoch 1/3; Step: 941/1407\n","Loss: 1.5804\n","\n","Epoch: 1/3\n","Loss: 1.8845288646754934\n","Accuracy: 45.4800%\n","F1Score: 45.4800%\n","\n","Epoch 2/3; Step: 1/1407\n","Loss: 1.2234\n","\n"]}],"source":["if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","TrainModel('SGD', 32, 0.005, 3)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate Model Accuracy\n","- Visualizations"]},{"cell_type":"markdown","metadata":{},"source":["# Test Set Predictions"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
